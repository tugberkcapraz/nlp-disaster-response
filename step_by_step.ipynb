{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tugberk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tugberk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tugberk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/tugberk/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# For Database connection\n",
    "from sqlalchemy import create_engine\n",
    "# For NLP related tasks\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'stopwords'])\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "# For data modelling and evaluating pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Saving the model\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tugberk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/tugberk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tugberk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/tugberk/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from models.train_classifier import load_data, tokenize, build_model, evaluate_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X, y, category_names = load_data(\"data/DisasterResponse.db\", \"PostEtl\")\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n       'medical_products', 'search_and_rescue', 'security', 'military',\n       'water', 'food', 'shelter', 'clothing', 'money', 'missing_people',\n       'refugees', 'death', 'other_aid', 'infrastructure_related', 'transport',\n       'buildings', 'electricity', 'tools', 'hospitals', 'shops',\n       'aid_centers', 'other_infrastructure', 'weather_related', 'floods',\n       'storm', 'fire', 'earthquake', 'cold', 'other_weather',\n       'direct_report'],\n      dtype='object')"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['AP 1:9-10/GAL 4:10-11/COL 2:14-18 ',\n       \"i would let every body know that the 4636 service for the emergency's information that i can't understand it \",\n       'i need water, 27 bertin street, Carrefour', ...,\n       'Due to the delays in obtaining clearance for the necessary cold chain logistics and vaccines for the immunisation component, the teams had to postpone their departure to the agreed project sites.',\n       'The people in Fontamara are starving. We are precisely in Trou Sable Madame Ganot. Please pass on the message',\n       'My wife and teenage children are not skilled in any particular trade but we will do whatever we can to help . My 13-year-old can take care of pets . My wife and 16-year-old daughter can help with child care . I can help with debris removal or other such tasks , such as delivering food/water to the elderly . ( My 86-year-old mother-in-law lives in a high rise on Pitt Street . )'],\n      dtype=object)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE()' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [22]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m \u001B[43mPipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m   \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mvectorizer\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCountVectorizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenize\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m   \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtfidf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mTfidfTransformer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msmote\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mSMOTE\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m   \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mclassifier\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mMultiOutputClassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCatBoostClassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                                                          \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# hyper-parameter grid\u001B[39;00m\n\u001B[1;32m      9\u001B[0m parameters \u001B[38;5;241m=\u001B[39m {\u001B[38;5;66;03m#'classifier__estimator__depth': [3,4,5],\u001B[39;00m\n\u001B[1;32m     10\u001B[0m               \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassifier__estimator__learning_rate\u001B[39m\u001B[38;5;124m'\u001B[39m:[\u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.3\u001B[39m]}\n",
      "File \u001B[0;32m~/Downloads/disaster_response_pipeline_project/venv/lib/python3.8/site-packages/sklearn/pipeline.py:148\u001B[0m, in \u001B[0;36mPipeline.__init__\u001B[0;34m(self, steps, memory, verbose)\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmemory \u001B[38;5;241m=\u001B[39m memory\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m=\u001B[39m verbose\n\u001B[0;32m--> 148\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_steps\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Downloads/disaster_response_pipeline_project/venv/lib/python3.8/site-packages/sklearn/pipeline.py:207\u001B[0m, in \u001B[0;36mPipeline._validate_steps\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    203\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mhasattr\u001B[39m(t, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(t, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit_transform\u001B[39m\u001B[38;5;124m\"\u001B[39m)) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\n\u001B[1;32m    205\u001B[0m         t, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransform\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    206\u001B[0m     ):\n\u001B[0;32m--> 207\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    208\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll intermediate steps should be \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    209\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransformers and implement fit and transform \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    210\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor be the string \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    211\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (type \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m) doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (t, \u001B[38;5;28mtype\u001B[39m(t))\n\u001B[1;32m    212\u001B[0m         )\n\u001B[1;32m    214\u001B[0m \u001B[38;5;66;03m# We allow last estimator to be None as an identity transformation\u001B[39;00m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    216\u001B[0m     estimator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(estimator, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfit\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    219\u001B[0m ):\n",
      "\u001B[0;31mTypeError\u001B[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SMOTE()' (type <class 'imblearn.over_sampling._smote.base.SMOTE'>) doesn't"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "   ('vectorizer', CountVectorizer(tokenizer=tokenize)),\n",
    "   ('tfidf', TfidfTransformer()),\n",
    "   ('classifier',MultiOutputClassifier(CatBoostClassifier(iterations=10,\n",
    "                                                          verbose=True)))\n",
    "])\n",
    "# hyper-parameter grid\n",
    "parameters = {'classifier__estimator__depth': [3,4,5],\n",
    "              'classifier__estimator__learning_rate':[0.1, 0.3]}\n",
    "\n",
    "# create model\n",
    "model = GridSearchCV(estimator=pipeline,\n",
    "                     param_grid=parameters,\n",
    "                     verbose=3,\n",
    "                     cv=3)\n",
    "model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.78      1.00      0.87      4041\n",
      "               request       0.81      0.35      0.49       948\n",
      "                 offer       0.00      0.00      0.00        25\n",
      "           aid_related       0.70      0.51      0.59      2198\n",
      "          medical_help       0.71      0.01      0.02       400\n",
      "      medical_products       0.86      0.02      0.04       268\n",
      "     search_and_rescue       0.33      0.01      0.03       149\n",
      "              security       0.00      0.00      0.00        83\n",
      "              military       0.00      0.00      0.00       167\n",
      "                 water       0.68      0.65      0.66       334\n",
      "                  food       0.75      0.77      0.76       587\n",
      "               shelter       0.83      0.47      0.60       471\n",
      "              clothing       0.78      0.26      0.39        81\n",
      "                 money       0.00      0.00      0.00       131\n",
      "        missing_people       0.55      0.11      0.19        53\n",
      "              refugees       0.77      0.12      0.21       192\n",
      "                 death       0.83      0.23      0.35       235\n",
      "             other_aid       0.00      0.00      0.00       709\n",
      "infrastructure_related       0.00      0.00      0.00       355\n",
      "             transport       0.82      0.06      0.11       249\n",
      "             buildings       0.78      0.11      0.20       270\n",
      "           electricity       1.00      0.01      0.02       106\n",
      "                 tools       0.00      0.00      0.00        27\n",
      "             hospitals       0.00      0.00      0.00        51\n",
      "                 shops       0.00      0.00      0.00        28\n",
      "           aid_centers       0.00      0.00      0.00        64\n",
      "  other_infrastructure       0.00      0.00      0.00       245\n",
      "       weather_related       0.89      0.53      0.67      1465\n",
      "                floods       0.92      0.50      0.64       440\n",
      "                 storm       0.78      0.51      0.62       485\n",
      "                  fire       0.00      0.00      0.00        54\n",
      "            earthquake       0.89      0.79      0.83       488\n",
      "                  cold       0.80      0.03      0.06       125\n",
      "         other_weather       0.00      0.00      0.00       290\n",
      "         direct_report       0.79      0.24      0.36      1029\n",
      "\n",
      "             micro avg       0.78      0.50      0.61     16843\n",
      "             macro avg       0.49      0.21      0.25     16843\n",
      "          weighted avg       0.68      0.50      0.53     16843\n",
      "           samples avg       0.71      0.48      0.52     16843\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tugberk/Downloads/disaster_response_pipeline_project/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tugberk/Downloads/disaster_response_pipeline_project/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/tugberk/Downloads/disaster_response_pipeline_project/venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=category_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'classifier__estimator__depth': 5,\n 'classifier__estimator__learning_rate': 0.1}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "for i in  range(len(y_train.columns)):\n",
    "   y_train[y_train.columns[i]] = y_train[y_train.columns[i]].map(lambda x : 1 if x == 2 else x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.related.max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "request\n",
      "offer\n",
      "aid_related\n",
      "medical_help\n",
      "medical_products\n",
      "search_and_rescue\n",
      "security\n",
      "military\n",
      "child_alone\n",
      "water\n",
      "food\n",
      "shelter\n",
      "clothing\n",
      "money\n",
      "missing_people\n",
      "refugees\n",
      "death\n",
      "other_aid\n",
      "infrastructure_related\n",
      "transport\n",
      "buildings\n",
      "electricity\n",
      "tools\n",
      "hospitals\n",
      "shops\n",
      "aid_centers\n",
      "other_infrastructure\n",
      "weather_related\n",
      "floods\n",
      "storm\n",
      "fire\n",
      "earthquake\n",
      "cold\n",
      "other_weather\n",
      "direct_report\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, df.shape[1], 1):\n",
    "   print(df.columns[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "40"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                            message  \\\n",
      "0   2  Weather update - a cold front from Cuba that c...   \n",
      "1   7            Is the Hurricane over or is it not over   \n",
      "2   8                    Looking for someone but no name   \n",
      "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
      "4  12  says: west side of Haiti, rest of the country ...   \n",
      "\n",
      "                                            original   genre  related  \\\n",
      "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
      "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
      "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
      "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
      "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
      "\n",
      "   request  offer  aid_related  medical_help  medical_products  ...  \\\n",
      "0        0      0            0             0                 0  ...   \n",
      "1        0      0            1             0                 0  ...   \n",
      "2        0      0            0             0                 0  ...   \n",
      "3        1      0            1             0                 1  ...   \n",
      "4        0      0            0             0                 0  ...   \n",
      "\n",
      "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
      "0            0                     0                0       0      0     0   \n",
      "1            0                     0                1       0      1     0   \n",
      "2            0                     0                0       0      0     0   \n",
      "3            0                     0                0       0      0     0   \n",
      "4            0                     0                0       0      0     0   \n",
      "\n",
      "   earthquake  cold  other_weather  direct_report  \n",
      "0           0     0              0              0  \n",
      "1           0     0              0              0  \n",
      "2           0     0              0              0  \n",
      "3           0     0              0              0  \n",
      "4           0     0              0              0  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "engine = create_engine('sqlite:///data/DisasterResponse.db')\n",
    "df = pd.read_sql_table('PostEtl', engine)\n",
    "print(df.head())\n",
    "# load model\n",
    "#model = joblib.load(\"../models/CatClassifier.pkl\")\n",
    "#print(\"model_loaded\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "genre_df = df.groupby('genre')['message'].count().reset_index()\n",
    "#genre_names = list(genre_counts.index.str.replace(\"_\", \" \").str.title())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0    direct\n1      news\n2    social\nName: genre, dtype: object"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_df[\"genre\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0    10766\n1    13054\n2     2396\nName: message, dtype: int64"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_df[\"message\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "    genre  message\n0  direct    10766\n1    news    13054\n2  social     2396",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>genre</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>direct</td>\n      <td>10766</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>news</td>\n      <td>13054</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>social</td>\n      <td>2396</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "   id                                            message  \\\n0   2  Weather update - a cold front from Cuba that c...   \n1   7            Is the Hurricane over or is it not over   \n2   8                    Looking for someone but no name   \n3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n4  12  says: west side of Haiti, rest of the country ...   \n\n                                            original   genre  related  \\\n0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n1                 Cyclone nan fini osinon li pa fini  direct        1   \n2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n\n   request  offer  aid_related  medical_help  medical_products  ...  \\\n0        0      0            0             0                 0  ...   \n1        0      0            1             0                 0  ...   \n2        0      0            0             0                 0  ...   \n3        1      0            1             0                 1  ...   \n4        0      0            0             0                 0  ...   \n\n   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n0            0                     0                0       0      0     0   \n1            0                     0                1       0      1     0   \n2            0                     0                0       0      0     0   \n3            0                     0                0       0      0     0   \n4            0                     0                0       0      0     0   \n\n   earthquake  cold  other_weather  direct_report  \n0           0     0              0              0  \n1           0     0              0              0  \n2           0     0              0              0  \n3           0     0              0              0  \n4           0     0              0              0  \n\n[5 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>message</th>\n      <th>original</th>\n      <th>genre</th>\n      <th>related</th>\n      <th>request</th>\n      <th>offer</th>\n      <th>aid_related</th>\n      <th>medical_help</th>\n      <th>medical_products</th>\n      <th>...</th>\n      <th>aid_centers</th>\n      <th>other_infrastructure</th>\n      <th>weather_related</th>\n      <th>floods</th>\n      <th>storm</th>\n      <th>fire</th>\n      <th>earthquake</th>\n      <th>cold</th>\n      <th>other_weather</th>\n      <th>direct_report</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Weather update - a cold front from Cuba that c...</td>\n      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n      <td>direct</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>Is the Hurricane over or is it not over</td>\n      <td>Cyclone nan fini osinon li pa fini</td>\n      <td>direct</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>Looking for someone but no name</td>\n      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n      <td>direct</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n      <td>direct</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12</td>\n      <td>says: west side of Haiti, rest of the country ...</td>\n      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n      <td>direct</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "df[\"len_msg\"] = df.message.str.len()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "           avg_len\ngenre             \ndirect   89.952071\nnews    193.183852\nsocial  127.186978",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>avg_len</th>\n    </tr>\n    <tr>\n      <th>genre</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>direct</th>\n      <td>89.952071</td>\n    </tr>\n    <tr>\n      <th>news</th>\n      <td>193.183852</td>\n    </tr>\n    <tr>\n      <th>social</th>\n      <td>127.186978</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"genre\")[\"len_msg\"].agg(avg_len = \"mean\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['id', 'message', 'original', 'genre'], dtype='object')"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[:4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "request\n",
      "offer\n",
      "aid_related\n",
      "medical_help\n",
      "medical_products\n",
      "search_and_rescue\n",
      "security\n",
      "military\n",
      "child_alone\n",
      "water\n",
      "food\n",
      "shelter\n",
      "clothing\n",
      "money\n",
      "missing_people\n",
      "refugees\n",
      "death\n",
      "other_aid\n",
      "infrastructure_related\n",
      "transport\n",
      "buildings\n",
      "electricity\n",
      "tools\n",
      "hospitals\n",
      "shops\n",
      "aid_centers\n",
      "other_infrastructure\n",
      "weather_related\n",
      "floods\n",
      "storm\n",
      "fire\n",
      "earthquake\n",
      "cold\n",
      "other_weather\n",
      "direct_report\n",
      "len_msg\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, df.shape[1], 1):\n",
    "    #print(df.loc[df[df.columns[i]] == 1][\"len_msg\"].mean())\n",
    "    print(df.columns[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "173.26316758747697"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.aid_related == 1][\"len_msg\"].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "col_names = []\n",
    "len_message = []\n",
    "for i in range(4, df.shape[1]-1, 1):\n",
    "    len_message.append(df.loc[df[df.columns[i]] == 1][\"len_msg\"].mean())\n",
    "    col_names.append(df.columns[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "36"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "36"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(len_message)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}